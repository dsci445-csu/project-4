---
title: "Data Cleaning"
author: "Dawson Carney"
date: "2025-11-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Alkalinity and Hardness Data

```{r}
library(dplyr)
library(tidyr)

# Match dates in alkalinity and hardness data
alk <- read.csv("RWAR_alkalinity.csv")
hardness <- read.csv("RWAR_hardness.csv")

# split DateStamp into day and time
alk_new <- separate(alk, col = DateStamp, into = c("Date", "Time"), sep = " ") |>
  select(-c("Time")) |>
  rename(alkalinity = Alkalinity..mg.L)
hardness_new <- separate(hardness, col = DateStamp, into = c("Date", "Time"), sep = " ") |>
  select(-c("Time")) |>
  rename(hardness = Hardness..mg.L)

# merge by Date
merged <- merge(alk_new, hardness_new, by="Date")

summary(merged) # Both alkalinity and hardness have zero-values (no data)

merged_clean1 <- merged[(merged$alkalinity != 0) & (merged$hardness != 0),] # remove

summary(merged_clean1) # no zero values, still a very large alkalinity value

tail(sort(merged_clean1$alkalinity)) # two significant outliers (equipment likely)

merged_clean2 <- merged[merged$alkalinity < 876, ] # remove outliers

summary(merged_clean2) # successfully removed zero values and outliers

```

```{r}
# output merged data to CSV (run after processing)

library(readr)
write_csv(merged_clean2, "alkalinity_hardness_cleaned.csv")

```

## Raw Water Data

```{r}

library(lubridate)
library(ggplot2)
library(zoo)
library(purrr)


## Import data, convert timestamp
rwar <- read.csv("RWAR_turb_cond_counts_pH_temp.csv")
rwar2 <- rwar |> mutate(DateTime = mdy_hm(rwar$Timestamp))
summary(rwar2)


## Temperature Data
# Plot
ggplot(rwar2) + geom_point(aes(x=DateTime, y=Temperature..deg.C))
# Find region of approx. zero temperature (outliers), set to NA
# Interpolate between nearest non-NA temperatures where temp is NA
rwar2_temp <- rwar2 |>
  select(c("DateTime", Temperature..deg.C)) |>
  mutate(temp_cleaned = ifelse(Temperature..deg.C < 1, NA, Temperature..deg.C)) |>
  mutate(temp_interp = na.approx(temp_cleaned, na.rm = FALSE))
# Average by day
rwar2_temp_daily <- rwar2_temp |>
  mutate(Day=date(DateTime)) |>
  group_by(Day) |>
  summarise(mean_Temp = mean(temp_interp))
ggplot(rwar2_temp_daily) + geom_point(aes(x=Day, y=mean_Temp))


## pH Data
# Plot
ggplot(rwar2) + geom_point(aes(x=DateTime, y=pH..SU))
# Does not seem like there are huge outliers, so average by day
rwar2_pH_daily <- rwar2 |>
  select(c("DateTime", pH..SU)) |>
  mutate(Day=date(DateTime)) |>
  group_by(Day) |>
  summarise(mean_pH = mean(pH..SU))
ggplot(rwar2_pH_daily) + geom_point(aes(x=Day, y=mean_pH))


## Conductivity Data
# Plot
ggplot(rwar2) + geom_point(aes(x=DateTime, y=Conductivity..mS.cm.1))
# Remove obvious outliers (only a few measurements; does not remove full days)
rwar2_cond <- rwar2 |> 
  select(c("DateTime", Conductivity..mS.cm.1)) |>
  filter(Conductivity..mS.cm.1 < 2 & Conductivity..mS.cm.1 > 0.2)
ggplot(rwar2_cond) + geom_point(aes(x=DateTime, y=Conductivity..mS.cm.1))
# Average by Day
rwar2_cond_daily <- rwar2_cond |>
  mutate(Day=date(DateTime)) |>
  group_by(Day) |>
  summarise(mean_Conductivity = mean(Conductivity..mS.cm.1))
ggplot(rwar2_cond_daily) + geom_point(aes(x=Day, y=mean_Conductivity))


## Turbidity Data
# Plot
ggplot(rwar2) + geom_point(aes(x=DateTime, y=Turbidity..NTU))
# Remove obvious outliers (only a few measurements; does not remove full days)
# Main obvious outliers are in mid 2019 and 2020, and are all above 7 NTU
rwar2_turb <- rwar2 |> 
  select(c("DateTime", Turbidity..NTU)) |>
  filter(Turbidity..NTU < 7)
ggplot(rwar2_turb) + geom_point(aes(x=DateTime, y=Turbidity..NTU))
# Average by Day
rwar2_turb_daily <- rwar2_turb |>
  mutate(Day=date(DateTime)) |>
  group_by(Day) |>
  summarise(mean_Turbidity = mean(Turbidity..NTU))
ggplot(rwar2_turb_daily) + geom_point(aes(x=Day, y=mean_Turbidity))

## Merge daily temp, pH, conductivity, turbidity

list_daily_data <- list(rwar2_temp_daily,
                        rwar2_pH_daily, 
                        rwar2_cond_daily,
                        rwar2_turb_daily)
merged_daily_data <- list_daily_data |>
  reduce(full_join, by = "Day") |>
  rename(Timestamp = Day)

```

```{r}
## Export CSV of cleaned raw water data

write_csv(merged_daily_data, )
```


<<<<<<< HEAD
```{r}
water_lm <- lm(Ferric.chloride..mg.L ~ ., 
               data=RWAR_dosing_cleaned |> select(-c(Timestamp, Cationic.Polimer..mg.L)))
summary(water_lm)

```

```{r}
data <- read.csv("RWAR_dosing_cleaned.csv")
lagged_data <- data |>
  mutate(Temp_lag1 = lag(mean_Temp, 1), 
         Temp_lag2 = lag(mean_Temp, 2),
         pH_lag1 = lag(mean_pH, 1),
         pH_lag2 = lag(mean_pH, 2),
         Cond_lag1 = lag(mean_Conductivity, 1),
         Cond_lag2 = lag(mean_Conductivity, 2),
         Turb_lag1 = lag(mean_Turbidity, 1),
         Turb_lag2 = lag(mean_Turbidity, 2))
# Temp
lagged_data$Temp_lag1[1] <- lagged_data$Temp_lag1[2]
lagged_data$Temp_lag2[1:2] <- lagged_data$Temp_lag2[3]
# pH
lagged_data$pH_lag1[1] <- lagged_data$pH_lag1[2]
lagged_data$pH_lag2[1:2] <- lagged_data$pH_lag2[3]
# Conductivity
lagged_data$Cond_lag1[1] <- lagged_data$Cond_lag1[2]
lagged_data$Cond_lag2[1:2] <- lagged_data$Cond_lag2[3]
# Turbidity
lagged_data$Turb_lag1[1] <- lagged_data$Turb_lag1[2]
lagged_data$Turb_lag2[1:2] <- lagged_data$Turb_lag2[3]

lagged_data
lm(Ferric.chloride..mg.L ~ ., data=lagged_data |> select(-c(Timestamp)))

```