---
title: "Data Cleaning"
author: "Dawson Carney"
date: "2025-11-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Alkalinity and Hardness Data

```{r}
library(dplyr)
library(tidyr)

# Match dates in alkalinity and hardness data
alk <- read.csv("RWAR_alkalinity.csv")
hardness <- read.csv("RWAR_hardness.csv")

# split DateStamp into day and time
alk_new <- separate(alk, col = DateStamp, into = c("Date", "Time"), sep = " ") |>
  select(-c("Time")) |>
  rename(alkalinity = Alkalinity..mg.L)
hardness_new <- separate(hardness, col = DateStamp, into = c("Date", "Time"), sep = " ") |>
  select(-c("Time")) |>
  rename(hardness = Hardness..mg.L)

# merge by Date
merged <- merge(alk_new, hardness_new, by="Date")

summary(merged) # Both alkalinity and hardness have zero-values (no data)

merged_clean1 <- merged[(merged$alkalinity != 0) & (merged$hardness != 0),] # remove

summary(merged_clean1) # no zero values, still a very large alkalinity value

tail(sort(merged_clean1$alkalinity)) # two significant outliers (equipment likely)

merged_clean2 <- merged[merged$alkalinity < 876, ] # remove outliers

summary(merged_clean2) # successfully removed zero values and outliers





```


